{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_movie_review.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP-oHCbOPmHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import dependencies and Downloading dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sentiment_tokenizer import Tokenizer\n",
        "import pickle\n",
        "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix\n",
        "tok=Tokenizer(preserve_case=False)\n",
        "import requests,io,os,tarfile\n",
        "r=requests.get('http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz')\n",
        "with open('aclImdb_v1.tar.gz','wb') as f:\n",
        "  f.write(r.content)\n",
        "z=tarfile.open('/content/aclImdb_v1.tar.gz','r:gz')\n",
        "os.mkdir('/content/imdb_movie_review')\n",
        "z.extractall('/content/imdb_movie_review')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjEv_16LOWlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split dataset into input and output\n",
        "def create_input_output(file):\n",
        "  # dataset=[]\n",
        "  input_data=[]\n",
        "  output_data=[]\n",
        "  for folder in os.listdir(file):\n",
        "    if(folder=='pos'):\n",
        "      for data in os.listdir(file+'/'+folder+\"/\"):\n",
        "        f=open(file+'/'+folder+'/'+data,'r')\n",
        "        data=f.read()\n",
        "        # dataset.append({\n",
        "        #     folder:data\n",
        "        # })\n",
        "        input_data.append(data)\n",
        "        output_data.append(folder)\n",
        "    if(folder=='neg'):\n",
        "      for data in os.listdir(file+'/'+folder+\"/\"):\n",
        "        f=open(file+'/'+folder+'/'+data,'r')\n",
        "        data=f.read()\n",
        "        # dataset.append({\n",
        "        #     folder:data\n",
        "        # })\n",
        "        input_data.append(data)\n",
        "        output_data.append(folder)\n",
        "  return input_data,output_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXPxCA7P0ATQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(sent):\n",
        "  train_review=[]\n",
        "  for review in sent:\n",
        "    s=''\n",
        "    words=tok.tokenize(review)\n",
        "    tokenized_words=[]\n",
        "    for word in words:\n",
        "      tokenized_words.append(word)\n",
        "    j=0\n",
        "    while(j<len(tokenized_words)):\n",
        "      k=0\n",
        "      if((\"n't\" in tokenized_words[j]) or(\"not\" in tokenized_words[j]) or (tokenized_words[j]=='.')):\n",
        "        s+=\" \"+tokenized_words[j]\n",
        "        index=j+1\n",
        "        i=index\n",
        "        while(i<len(tokenized_words)):\n",
        "          if(tokenized_words[i]!='but' and tokenized_words[i]!='and' and tokenized_words[i]!='.' and tokenized_words[i]!=','):\n",
        "            s+=\" NOT_\"+tokenized_words[i]\n",
        "            i+=1\n",
        "            k=i\n",
        "          else:\n",
        "            s+=\" \"+tokenized_words[i]\n",
        "            i+=1\n",
        "            k=i\n",
        "            break\n",
        "      else:\n",
        "        s+=\" \"+tokenized_words[j]\n",
        "      if(k==0):\n",
        "        j+=1\n",
        "      else:\n",
        "        j=k\n",
        "    train_review.append(s)\n",
        "  return train_review"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEXCNvT1lcep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize(input_data):\n",
        "  vect=TfidfVectorizer()\n",
        "  vect=vect.fit(input_data)\n",
        "  input_data=vect.transform(input_data)\n",
        "  return vect,input_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onnZbH30nj9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_encoding(output_data):\n",
        "  le=LabelEncoder()\n",
        "  output_data=le.fit_transform(output_data)\n",
        "  return le,output_data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mPFpLtr3UOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SVM\n",
        "from sklearn import svm\n",
        "def model_support_vector_machine(input_data,output_data):\n",
        "  model_svm=svm.SVC(gamma='scale')\n",
        "  model_svm.fit(input_data,output_data)\n",
        "  return model_svm"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeag2lQWoLr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_data(file):\n",
        "  test_dataset=[]\n",
        "  test_input_data=[]\n",
        "  test_output_data=[]\n",
        "  for folder in os.listdir(file):\n",
        "    if(folder=='pos'):\n",
        "      for data in os.listdir(file+'/'+folder+\"/\"):\n",
        "        f=open(file+'/'+folder+'/'+data,'r')\n",
        "        data=f.read()\n",
        "        test_dataset.append({\n",
        "            folder:data\n",
        "        })\n",
        "        test_input_data.append(data)\n",
        "        test_output_data.append(folder)\n",
        "    if(folder=='neg'):\n",
        "      for data in os.listdir(file+'/'+folder+\"/\"):\n",
        "        f=open(file+'/'+folder+'/'+data,'r')\n",
        "        data=f.read()\n",
        "        test_dataset.append({\n",
        "            folder:data\n",
        "        })\n",
        "        test_input_data.append(data)\n",
        "        test_output_data.append(folder)\n",
        "  return test_input_data,test_output_data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l_r8iw-C9L7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluating_model(Y_true,Y_pred):\n",
        "  matrix=confusion_matrix(Y_true,Y_pred)\n",
        "  precision=precision_score(Y_true,Y_pred)\n",
        "  recall=recall_score(Y_true,Y_pred)\n",
        "  f1=f1_score(Y_true,Y_pred)\n",
        "  return matrix,precision,recall,f1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "785Ze9MH_DoS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "1d7a392f-4638-432a-925a-725e4671b7d1"
      },
      "source": [
        "print(\"*************Training Time***********************\")\n",
        "input_data,output_data=create_input_output(\"/content/imdb_movie_review/aclImdb/train\")\n",
        "input_data=preprocessing(input_data)\n",
        "vect,input_data=vectorize(input_data)\n",
        "le,output_data=label_encoding(output_data)\n",
        "\n",
        "print(\"Training SVM model:\\n\")\n",
        "model_svm=model_support_vector_machine(input_data,output_data)\n",
        "print(\"SVM model trained successfully\\n\")\n",
        "print(\"Training Accuracy:\",model_svm.score(input_data,output_data))\n",
        "\n",
        "print(\"*************Testing Time***********************\")\n",
        "test_input_data,test_output_data=get_test_data(\"/content/imdb_movie_review/aclImdb/test\")\n",
        "test_input_data=preprocessing(test_input_data)\n",
        "test_input_data=vect.transform(test_input_data)\n",
        "test_output_data=le.transform(test_output_data)\n",
        "\n",
        "print(\"Evaluating SVM model:\\n\")\n",
        "print(\"Testing Accuracy:\",model_svm.score(test_input_data,test_output_data))\n",
        "predicted_value=model_svm.predict(test_input_data)\n",
        "matrix,precision,recall,f1=evaluating_model(test_output_data,predicted_value)\n",
        "print(\"Confusion matrix:- \",matrix)\n",
        "print(\"Precision:- \",precision)\n",
        "print(\"Recall:- \",recall)\n",
        "print(\"f1 score:- \",f1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************Training Time***********************\n",
            "Training SVM model:\n",
            "\n",
            "SVM model trained successfully\n",
            "\n",
            "*************Testing Time***********************\n",
            "Evaluating SVM model:\n",
            "\n",
            "Accuracy: 0.88636\n",
            "Confusion matrix:-  [[11104  1396]\n",
            " [ 1445 11055]]\n",
            "Precision:-  0.8878804915267849\n",
            "Recall:-  0.8844\n",
            "f1 score:-  0.8861368281832391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAkX6Se6dOFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('model.pkl','wb') as f:\n",
        "  pickle.dump(model_svm,f)\n",
        "with open('vect.pkl','wb') as f:\n",
        "  pickle.dump(vect,f)\n",
        "with open('le.pkl','wb') as f:\n",
        "  pickle.dump(le,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2DlRjprTHTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}